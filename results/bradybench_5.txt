
================================================================================
For the given C code
 ```c++ 
#pragma ACCEL kernel

void top(float radiative_flux_up[80][80][10],float radiative_flux_down[80][80][10],float absorption[80][80][10],float scattering[80][80][10],float reflectivity[80][80][10])
{
  float balance;
  float new_flux_up[80][80][10];
  float new_flux_down[80][80][10];
  
#pragma ACCEL PIPELINE auto{__PIPE__L0}
  
#pragma ACCEL TILE FACTOR=auto{__TILE__L0}
  for (int t = 0; t < 5; t++) {
    
#pragma ACCEL PIPELINE auto{__PIPE__L1}
    
#pragma ACCEL TILE FACTOR=auto{__TILE__L1}
    for (int z = 1; z < 10 - 1; z++) {
      
#pragma ACCEL PIPELINE auto{__PIPE__L4}
      
#pragma ACCEL TILE FACTOR=auto{__TILE__L4}
      
#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L4}
      for (int i = 0; i < 80; i++) {
        
#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L7}
        for (int j = 0; j < 80; j++) {
          new_flux_up[i][j][z] = radiative_flux_up[i][j][z] * (((float )1) - absorption[i][j][z]) + radiative_flux_down[i][j][z] * scattering[i][j][z] + radiative_flux_up[i][j][z - 1] * reflectivity[i][j][z];
          new_flux_down[i][j][z] = radiative_flux_down[i][j][z] * (((float )1) - absorption[i][j][z]) + radiative_flux_up[i][j][z] * scattering[i][j][z] + radiative_flux_down[i][j][z + 1] * reflectivity[i][j][z];
        }
      }
    }
    
#pragma ACCEL PIPELINE auto{__PIPE__L2}
    
#pragma ACCEL TILE FACTOR=auto{__TILE__L2}
    
#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L2}
    for (int i = 0; i < 80; i++) {
      
#pragma ACCEL PIPELINE auto{__PIPE__L5}
      
#pragma ACCEL TILE FACTOR=auto{__TILE__L5}
      
#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L5}
      for (int j = 0; j < 80; j++) {
        new_flux_up[i][j][0] = radiative_flux_up[i][j][0];
        new_flux_down[i][j][10 - 1] = radiative_flux_down[i][j][10 - 1];
        for (int z = 0; z < 10; z++) {
          radiative_flux_up[i][j][z] = new_flux_up[i][j][z];
          radiative_flux_down[i][j][z] = new_flux_down[i][j][z];
        }
      }
    }
    
#pragma ACCEL PIPELINE auto{__PIPE__L3}
    
#pragma ACCEL TILE FACTOR=auto{__TILE__L3}
    for (int z = 0; z < 10; z++) {
      
#pragma ACCEL PIPELINE auto{__PIPE__L6}
      
#pragma ACCEL TILE FACTOR=auto{__TILE__L6}
      
#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L6}
      for (int i = 0; i < 80; i++) {
        
#pragma ACCEL PARALLEL FACTOR=auto{__PARA__L9}
        for (int j = 0; j < 80; j++) {
          balance = radiative_flux_up[i][j][z] - radiative_flux_down[i][j][z];
          absorption[i][j][z] = (balance > ((float )0)?balance * 0.1f : ((float )0));
        }
      }
    }
  }
}

``` with some pragma placeholders for high level synthesis (HLS), your task is to choose one of the following updates that optimize clock cycles the most.
(0): change __PARA__L4 from 80 to 16
Note that when:
the value of __PARA__L4 is 80
The kernel's results after HLS synthesis are:
 
To better understand the problem, here are some knowledge about the HLS pragmas you are encountering:
 For the __PARA__ pragma:
  (1) Parallel pragram will parallelize the first for loop in the c code under __PARA__.
  (2) Increasing the parallel factor will increase the resource utilization but improve the performance and decease the number of cycles (which is one of your target).
  (3) Increasing parallel factor roughly linearly increase the resource utilization within the loop it applies on, so you may scale the factor with respect to the ratio between current utilization with the 80% budget.
  (4) Increasing the parallel factor will also increase the compilation time, you must decrease the parallel factor if you received the compilation timeout.
 For the __TILE__ pragma:
  (1) Tile pragma will tile the first for loop in the c code under __TILE__.
  (2) Increasing the tile factor will reduce the memory transfer cycles because it will restrict the memory transfer.
 For the __PIPE__ pragma:
  (1) Pipeline pragma will affect MULTIPLE loops under __PIPELINE__.
  (2) The flatten option will unroll all the for loops (which means putting __PARA__ equals to the loop bound in the for loop) under this pragma.
  (3) Turning off the pipeline will not apply any pipelining, which is useful when you get compilation timeout in the report.
  (4) Choosing the empty string means coars-grained pipelining, which is useful when you believe the loop inside it has fewer loop-carried dependencies.
To make better decision, here are some information about the preference:
  (1) You should prioritize optimizing the __PARA__ pragma first, as it affect the performance the most.
  (2) If you think all the parallel factors are already optimal, you consider pipeline as the secondary choice. When doing so, you must remember that the pipeline pragma will affect MULTIPLE loops. The flatten option will unroll all the for loops under this pragma. Turning off the pipeline will not apply any pipelining, which is useful when you get compilation timeout in the report.
  (3) If you think all the parallel factors are already optimal, and the pipeline pragma is already optimal, you can consider the tile pragma. The tile pragma will tile the first for loop in the c code under __TILE__.
  (4) By default, setting __TILE__ to 1 is perferable.
  (5) By default, setting __PIPE__ to 1 is perferable.
Make the update to the current design and output only the new pragma design for the keys: __PARA__L4as a JSON string. i.e., can be represented as {"pragma1": value1, "pragma2": value2, ...}
--------------------------------------------------------------------------------
```json
{"__PARA__L4": 80}
```